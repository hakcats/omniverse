{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dffa7ef-c396-4b3b-97f7-e8bff62a5ae6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5817dfa-4024-48a5-a3c4-0c742533636b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import faiss \n",
    "\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from scipy.io.wavfile import read, write\n",
    "\n",
    "import lipsync\n",
    "import lipsync_grpc\n",
    "\n",
    "import grpc\n",
    "from lipsync_utilities import push_audio_track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7505a84e-2e88-41d7-aaab-5bc46c9ab737",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Create Custom Dataset for Question Answering\n",
    "Use a question answering dataset. ***You can use your own dataset.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9a036d-a8eb-4cb3-b02a-98c19b6f6bcb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1-1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2a227c-cac0-4f92-aa1b-8d6ca5297d56",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "qa_data_2 = pd.read_csv('data/dataset.csv')\n",
    "qa_data_2 = qa_data_2.dropna()\n",
    "qa_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07d6cc7-1f00-415a-acb4-94a3e023f9c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1-2. Preprocessing\n",
    "Remove icons from the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432f7d7c-6d68-4718-a793-c6a5c27bff18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "qa_data_2['question'] = qa_data_2.question.str.replace('[^\\w\\s]','')\n",
    "qa_data_2['answer'] = qa_data_2.answer.str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7080ce-a268-443a-af16-431f8464f32b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href='https://www.sbert.net/'>Sentence-Transformer</a> is for state-of-the-art sentence, text and image embeddings that can encode sentence into feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99aa578e-2977-4df1-a243-9eff7a0b02b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-xlm-r-multilingual-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332d416b-59c3-45df-a32d-dbd8aa6837c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1-4. Sentence Embedding For The Question Answering Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1278c8-af24-4f29-88ac-61e43b6f08ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sentence_embedded = model.encode(qa_data_2.question.values)\n",
    "print(sentence_embedded.shape)\n",
    "\n",
    "# Save the feature vectors as .npy file\n",
    "with open('./sentence_2_vector/sentence_embedded.npy', 'wb') as f:\n",
    "    np.save(f, sentence_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b8e9237-c8e0-4b37-b01f-a3830db094b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load feature vectors \n",
    "with open('./sentence_2_vector/sentence_embedded.npy', 'rb') as f:\n",
    "    sentence_embedded = np.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Faiss For Semantic Search\n",
    "We’ll conduct a similarity search, comparing a user input question to a list of FAQs and return the most likely answers by <a href='https://ai.facebook.com/tools/faiss'>Facebook’s Similarity Search API</a>.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e09a3a45-42e1-4921-acdc-6f2a236d59a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d = sentence_embedded.shape[1]  # The length of each feature vector\n",
    "nb = sentence_embedded.shape[0] # Number of dataset records\n",
    "nq = 1 # Number of query\n",
    "index = faiss.IndexFlatL2(d)       \n",
    "index.add(sentence_embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f40429-d9ce-4bf8-8b0e-4ec01bd45f0f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f725bf72-2d66-4a3b-b099-6ea263c189cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "asr=sr.Recognizer()\n",
    "\n",
    "def get_str_answer(str_question, top_k=5):\n",
    "\n",
    "    global model\n",
    "    global index\n",
    "    global qa_data_2\n",
    "    \n",
    "    input_question = model.encode([str_question])\n",
    "    D, I = index.search(input_question, top_k)\n",
    "    return qa_data_2.iloc[I[0]].sample().answer.values[0]\n",
    "\n",
    "def speech_to_text(audio):\n",
    "    global asr\n",
    "    try:\n",
    "        return True, asr.recognize_google(audio, language=\"zh-TW\")\n",
    "    except Exception as e:\n",
    "        return False, e.__class__\n",
    "\n",
    "def answer(str_question):\n",
    "    str_response = get_str_answer(str_question)\n",
    "    make_avatar_speaks(str_response)\n",
    "    return \n",
    "\n",
    "def get_tts_data(text):\n",
    "    tts_result = io.BytesIO()\n",
    "    tts = gTTS(text=text, lang='zh-TW', slow=False)\n",
    "    tts.write_to_fp(tts_result)\n",
    "    tts_result.seek(0)\n",
    "    return tts_result.read()\n",
    "\n",
    "def tts_to_wav(tts_byte, framerate=22050):\n",
    "    seg=AudioSegment.from_mp3(io.BytesIO(tts_byte))\n",
    "    seg=seg.set_frame_rate(framerate)\n",
    "    seg=seg.set_channels(1)\n",
    "    wavIO=io.BytesIO()\n",
    "    seg.export(wavIO, format=\"wav\")\n",
    "    rate, wav = read(io.BytesIO(wavIO.getvalue()))\n",
    "    return wav\n",
    "\n",
    "def wav_to_numpy_float32(wav_byte):\n",
    "    return wav_byte.astype(np.float32, order='C') / 32768.0\n",
    "\n",
    "def get_tts_numpy_audio(text):\n",
    "    mp3_byte = get_tts_data(text)\n",
    "    wav_byte = tts_to_wav(mp3_byte)\n",
    "    return wav_to_numpy_float32(wav_byte)\n",
    "\n",
    "def make_avatar_speaks(text):\n",
    "    global a2f_url\n",
    "    global sample_rate\n",
    "    global a2f_avatar_instance\n",
    "    push_audio_track(a2f_url, get_tts_numpy_audio(text), sample_rate, a2f_avatar_instance)\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e039b06-98d3-40f2-9a20-752c6c8b3013",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Avatar demo\n",
    "***Make sure Omniverse audio2face is running in streaming mode to interact with our program.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e3f9f5-2591-4dc5-9386-f28cee90d3a2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<iframe\n",
    "  src=\"https://carbon.now.sh/embed?bg=rgba%28171%2C+184%2C+195%2C+1%29&t=seti&wt=none&l=auto&ds=true&dsyoff=20px&dsblur=68px&wc=true&wa=true&pv=56px&ph=56px&ln=false&fl=1&fm=Hack&fs=14px&lh=133%25&si=false&es=2x&wm=false&code=from%2520IPython.display%2520import%2520YouTubeVideo%250A%2523%2520YouTubeVideo%28id%252C%2520with%252C%2520height%252C%2520start%2520%253D%2520start_time%29%250AYouTubeVideo%28id%2520%253D%2520%271j_HxD4iLn8%27%252C%2520width%253D400%252C%2520height%253D300%252C%2520start%2520%253D%252020%29\"\n",
    "  style=\"width: 715px; height: 242px; border:0; transform: scale(1); overflow:hidden;\"\n",
    "  sandbox=\"allow-scripts allow-same-origin\">\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782256df-68bc-45ac-a055-361bc019344c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Talk to your avatar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e10503aa-7342-474c-ae1a-af3f0dd14d06",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a2f_url = 'localhost:50051'\n",
    "sample_rate = 22050 # frame rate\n",
    "a2f_avatar_instance = '/audio2face/player_instance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fad57f-09ae-4600-b5cd-7816427a306e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with sr.Microphone() as source:\n",
    "    asr.adjust_for_ambient_noise(source, duration=5)\n",
    "    print('Say something')\n",
    "    audio=asr.listen(source)\n",
    "    is_valid_input, _input = speech_to_text(audio)\n",
    "    if is_valid_input:\n",
    "            answer(_input)\n",
    "    else:\n",
    "        if _input is sr.UnknownValueError:\n",
    "            make_avatar_speaks('Sorry, I could not hear what you said.')\n",
    "        elif _input is sr.RequestError:\n",
    "            print(\"No response from Speech Recognition service: {0}\".format(_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71822649-9d8e-4321-95dc-69fc51426afb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}